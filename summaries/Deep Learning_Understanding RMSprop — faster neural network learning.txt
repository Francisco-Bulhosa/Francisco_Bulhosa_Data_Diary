URL: https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a
Summary: RMSprop is an adaptive learning rate optimization algorithm proposed by Geoff Hinton for neural networks. It adapts the step size individually for each weight and combines ideas from rprop and Adagrad. The algorithm keeps a moving average of squared gradients, dividing the gradient by the square root of the mean square. RMSprop is fast and widely used in deep learning. It outperforms some other optimization algorithms in situations like saddle points and large initial gradients. For more on optimization in deep learning, there are various sources to explore.
